# 29_歧视偏见
Discrimination / Bias

AI learning unhealthy stereotypes 人工智能学习不健康的刻板印象
- Man：Woman as Father：Mother
- Man：Woman as King：Queen
- Man：Computer programmer as Woman：？Homemaker x（Computer programmer），技术层面上讲，是由于单词存储形式，加上推理造成的
    - Man：（1，1）
    - Computer programmer：（3，2）
    - Woman：（2，3）
    - Homemaker：（4，4）
    - Man -> Computer programmer 相当于 X 坐标加 2，Y 坐标加 1，同理 Woman X 加 2，Y 加 1 得到坐标 （4，4），而 AI 正好学习到的单词是 Homemaker，造成歧视 

    Why bias matters
    - Hiring tool that discriminated against women 歧视女性的招聘工具
    - Facial recognition working better for light-skinned than dark-skinned individuals 人脸识别对浅色皮肤的人比对深色皮肤的人更有效
    - Bank loan approvals 银行贷款审批
    - Toxic effect of reinforcing unhealthy stereotypes 强化不健康刻板印象的毒性作用

Combating bias
- Technical solutions:
    - E.g. "zero out" the bias in words 消除词语中的偏见
    - Use less biased and/or more inclusive data 使用歧视性少的数据更多的包容性数据
- Transparency and/or auditing processes 透明和可审计的过程
- Diverse workforce 多元化员工，有助于消除歧视

虽然让 AI 减少歧视比人类容易，但我们仍需从技术上和非技术上努力，让 AI 决策时，更少的偏见且更公平。